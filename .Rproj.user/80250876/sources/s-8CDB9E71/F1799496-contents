############################################################
# Header: some directory/sourcing info
############################################################
rm(list=ls(all=TRUE))

# Set wd to source location:
setwd("~/Dropbox/Bayesian_FAR/JBES/FINAL/Submit/Supplementary Files/R code and data")

# Some data specs:
useDifferences = FALSE  # Difference the yield data?
yieldType = "Real"      # "Nominal" or "Real"
h = 5                   # Include 1- and h-step forecasts

# Dates to include:
startDateSeq = c(
  as.Date("2003-02-01"),
  as.Date("2004-08-01"),
  as.Date("2006-02-01"),
  as.Date("2007-08-01"),
  as.Date("2009-02-01"),
  as.Date("2010-08-01"),
  as.Date("2012-02-01"),
  as.Date("2013-08-01"), 
  as.Date("2015-02-01")
)
endDateEstimateSeq = c(
  as.Date("2004-08-01"),
  as.Date("2006-02-01"),
  as.Date("2007-08-01"),
  as.Date("2009-02-01"),
  as.Date("2010-08-01"),
  as.Date("2012-02-01"),
  as.Date("2013-08-01"),
  as.Date("2015-02-01"),
  as.Date("2016-08-01")
)
endDateForecastSeq = c(
  as.Date("2004-09-01"),
  as.Date("2006-03-01"),
  as.Date("2007-09-01"),
  as.Date("2009-03-01"),
  as.Date("2010-09-01"),
  as.Date("2012-03-01"),
  as.Date("2013-09-01"),
  as.Date("2015-03-01"),
  as.Date("2016-09-01")
)

Niters = length(startDateSeq)
############################################################
# Model specifications
############################################################
pMax = 1; selectLagP = FALSE                   # either the max lag (selectLagP = TRUE) in the selection procedure or the fixed choice of the lag (selectLagP = FALSE)
useFDLM = TRUE                                 # Use FDLM on FAR (evolution) errors, or Matern GP?

nsims = 10000; burnin = 5000; thin = 1;			 # MCMC parameters

############################################################
# Packages:
############################################################
library(fda); library(MCMCpack); library(vars); library(KFAS); library(dlm); library(FastGP); library(truncdist); library(forecast)

# For simulations:
library(fGarch); library(geoR); library(plot3D)
# This may improve efficiency in some cases:
library(compiler);  enableJIT(3)

# Import Slice sampler from Neal
source("sliceSampling.R")

# Import functions:
source("farSourceFunctions.R")

############################################################
# Read in the data:
  # Rownames are the dates, column names are the maturities (months)
############################################################
if(yieldType == "Real") load('real.RData')
if(yieldType == "Nominal") load('nominal.RData')
Yall = Y; tauAll0 = as.numeric(colnames(Yall)); dates = as.Date(paste(rownames(Yall)))

# Storege:
errAll = errAllh = array(0, c(Niters, 9)); colnames(errAll) = colnames(errAllh) = c('RW', 'Mean', 'SES', 'VAR-Y', 'DRA06','DRA06init', 'FAR Classic', 'VAR-FPC', 'FAR')
compTimesAll = JeAll = rhoAll = numeric(Niters) 
if(selectLagP) propSelectedAll = matrix(0, nr=Niters, nc=pMax)

timer0 = proc.time()[3]			# for timing the entire sampler
for(niter in 1:Niters){
  
  # For reproducibility:
  set.seed(14850)
  
  # Obtain local (niter) starting/ending dates:
  startDate = startDateSeq[niter]; endDateEstimate = endDateEstimateSeq[niter]; endDateForecast = endDateForecastSeq[niter]
  
  # Restrict to estimation and forecast periods:
  useIndsFore = which(1.0*(dates >= startDate)*(dates <= endDateForecast)*(rowSums(!is.na(Yall)) > 0) ==1) 
  useIndsEst = which(1.0*(dates >= startDate)*(dates <= endDateEstimate)*(rowSums(!is.na(Yall)) > 0) ==1) 
  
  Ytot = Yall[useIndsFore,]; Y = Yall[useIndsEst,]
  if(useDifferences){Ytot = diff(Ytot); Y = diff(Y)}
  Ttot = nrow(Ytot); T = nrow(Y); forHoriz = Ttot - T
  
  # Subset the maturities (based on NAs):
  useInds = which(colSums(!is.na(Y)) > 0); tau0 = tauAll0[useInds]; Y = Y[,useInds]; Ytot = Ytot[,useInds]
  
  # Subset the dates (based on NAs):
  useInds = which(rowSums(!is.na(Ytot)) > 0); Ytot = Ytot[useInds,]
  useInds = which(rowSums(!is.na(Y)) > 0); Y = Y[useInds,]
  
  tauObs = (tau0 - min(tau0))/(diff(range(tau0))); 
  mObs = length(tauObs);  # number of total observations points
  
  mtbar = mObs # For this application, should be fine
  
  # Obtain the evaluaton points, update Y, and store "joint" points (tauAll)
  Yobs = as.matrix(Y); Ytotobs = as.matrix(Ytot)
  evalLs = getEvalPoints(as.matrix(Y), tauObs, mEval = max(20, mObs)); Y = evalLs$Yall; tauAll = evalLs$tauAll; mAll = evalLs$mAll; tauEval = evalLs$tauEval; mEval = length(tauEval)
  Ytot = getEvalPoints(as.matrix(Ytot), tauObs, mEval = max(20, mObs))$Yall; 
  tauEval0 = tauEval*diff(range(tau0)) + min(tau0) # on the original scale
  
  # Convert to integers for interpretability:
  #tauEval0 = round(tauEval0); allDups = duplicated(tauEval0); while(sum(allDups > 0)) {tauEval0[allDups] = tauEval0[allDups] + 1; allDups = duplicated(tauEval0)}
  tauEval = tauAll = (tauEval0 -min(tau0))/diff(range(tau0))
  
  # Evaluate at these points:
  tau_star = sort(union(tauEval, seq(0, 1, length.out = 50))); 

  plot(as.ts(Ytotobs[,1:min(10, ncol(Ytotobs))]), main = startDate)
  
  ############################################################
  # Internal options and preliminary computatations :
  ############################################################
  # Additional FDLM parameters:
  fixSigma_eta = FALSE; tolFPC = 0.95	              # fix approx error variance for smoother mu_t? PVE for SVD init? 
  sampleFLCs = TRUE #(sum(colMeans(!is.na(Y)) > 0) >=  5) # if we observe fewer than 5 points, don't sample FLCs (just orthog. the spline basis)
  sampleKappas = FALSE                              # Sample kappa_s (stationarity prior precision), or leave at kappa_s = 1?
  ############################################################
  
  ############################################################
  # Basis Functions and Integral/Penalty matrices:
  ############################################################
  # Compute the basis/penalty/prior information for the FAR kernel:
  psiInfo = getPsiInfo(tauEval, m = mtbar, pMax = pMax)
  
  # Basis and priors for intercept/mean function (sigma_u is the prior SD corresp. to the smoothing par.)
  #B0 = getLowRankTPS(tauAll, m = sum(colMeans(!is.na(Y)) > 0)); sigma_u = 1; coefPriorPrec = diag(c(rep(10^-8, 2), rep(sigma_u^-2, ncol(B0)-2)))
  B0star = getLowRankTPS(tau_star, m = sum(colMeans(!is.na(Y)) > 0)); B0 = B0star[match(tauAll, tau_star),]; sigma_u = 1; coefPriorPrec = diag(c(rep(10^-8, 2), rep(sigma_u^-2, ncol(B0)-2)))
  
  # Useful index:
  p.inds= seq(1, mEval*(pMax+1), by=mEval)                  
  ############################################################
  # Parameter initialization  
  ############################################################
  # Initialize the overall mean 
  initMuInt = initMean(Y, B0, coefPriorPrec); muInt0 = muInt = initMuInt$muInt; thetaInt = initMuInt$thetaInt; muIntInfo = initMuInt$muIntInfo; 
  muIntRep = tcrossprod(rep(1, T), muInt) # For easy comparisons w/ mu (below)
  sigma_u = sqrt(sum(thetaInt[-(1:2)]^2)/(ncol(B0)-2)); diag(coefPriorPrec)[-(1:2)] = sigma_u^-2 # Prior precision for thetaInt
  
  # Initialize mu_t's using a spline fit (w/ common smoothing parameter)
  mu = smoothMuInit(Y - muIntRep, tauAll, tauEval); 
  muTot = muIntRep; muTot[,match(tauEval, tauAll)] = muTot[,match(tauEval, tauAll)] + mu # estimates of E[Y_t]
  
  # Measurement/observation error variance:
  sigma_nu = sqrt(sum((Y - muTot)^2, na.rm=TRUE)/sum(!is.na(Y)))		
  
  # FAR kernel:
  farInit = initFARkernel(psiInfo, mu, pMax); Gp = farInit$Gp; Gp1 = farInit$Gp1; theta_psiS = farInit$theta_psiS; farParams = farInit$farParams
  
  # Evolution equation residuals:
  evoResids = mu; for(nj in (1:pMax)) evoResids[(pMax+1):T,] = evoResids[(pMax+1):T,] - tcrossprod(mu[((pMax+1):T - nj),], Gp[,p.inds[nj]:(p.inds[nj+1] - 1)])
  
  # Initialize the evolution error covariance (+ associated parameters)
  if(useFDLM){
    #fdlmIn = initFDLM(tauEval, mtbar, evoResids, fixSigma_eta, tolFPC, sampleFLCs, Je = 3, tau_star); covParams = fdlmIn$covParams; fdlmParams = fdlmIn$fdlmParams
    fdlmIn = initFDLM(tauEval, mtbar, evoResids, fixSigma_eta, tolFPC, sampleFLCs, Je = NULL, tau_star); covParams = fdlmIn$covParams; fdlmParams = fdlmIn$fdlmParams
    PhiMat = covParams$PhiMat; sigmaj2 = covParams$sigmaj2; sigma_eta = covParams$sigma_eta
    
    # Compute the innovation covariance and its inverse using the FDLM simplifications:
    Keps = Kfun(PhiMat, diag(sigmaj2), sigma_eta)
    KepsInv = Kinvfun(PhiMat, sigmaj2, sigma_eta)
    
  } else { 
    # Matern GP, using the following correlation function:
    if(require(geoR)){ # I've had some issues with this package
      corrFun = function(d,rho) cov.spatial(d, cov.model='matern', cov.pars=c(1,rho), kappa = 2.5) 			
    } else {corrFun = function(d,rho) (1 + sqrt(5)*d/rho + 5*d^2/(3*rho^2))*exp(-sqrt(5)*d/rho)}
    gpIn = initGP(evoResids, tauEval); Keps = gpIn$Keps; KepsInv = gpIn$KepsInv; gpParams = gpIn$gpParams; rhoInfo = gpIn$rhoInfo
  }
  
  # Set up and store the DLM's (for estimation AND forecasting) using KFAS structures:
  dlmIn = initDLMs(Y, Gp, pMax, Ytot); Models = dlmIn$Models; ModelsFore = dlmIn$ModelsFore
  muFore =  muForeH = matrix(0, nr=Ttot-T, nc=mAll)
  
  # And initialize the states and transition probabilities: 
  # q01 = P(sj[j] = 1 | sj[j-1] = 0), q10 = P(sj[j] = 0 | sj[j-1] = 1)
  sj = numeric(pMax) + 1; q01 = 0.01; q10 = 0.75
  
  ############################################################
  # MCMC parameters to save (Note: could save many more)
  ############################################################
  postMuTotFore = postMuTotForeH = array(0, c((nsims-burnin)/thin, Ttot - T, mAll))
  if(selectLagP) postSj = array(0, c((nsims-burnin)/thin, pMax))
  ############################################################
  timeri = proc.time()[3]
  for(nsi in 1:nsims){
    
    ######################################################
    # Sample the states and transition probabilities:
    ######################################################
    #if(selectLagP){samplesj = samplePsiStates(sj, q01, q10, mu, Gp, Gp1, KepsInv, probS1equalsOne = 0.9, randomizeOrder = (nsi > burnin/2)); sj = samplesj$sj; Gp = samplesj$Gp}
    if(selectLagP && nsi > 100){samplesj = samplePsiStates(sj, q01, q10, mu, Gp, Gp1, KepsInv, probS1equalsOne = 0.9, randomizeOrder = (nsi > burnin/2)); sj = samplesj$sj; Gp = samplesj$Gp}
    ######################################################
    # Sample the FAR kernel operator(s) and associated parameters:
    ######################################################
    farSamp = sampleFARkernel(Gp, psiInfo, mu, KepsInv, sj, farParams, pMax, sampleKappas); Gp = farSamp$Gp; Gp1 = farSamp$Gp1; theta_psiS = farSamp$theta_psiS; farParams = farSamp$farParams
    ######################################################
    # Evolution error covariance function
    ######################################################
    # Compute the evolution errors (only loop over those for which sj[j] != 0)
    allj = 1:pMax; allj = allj[which(sj==1)]; evoResids = mu; for(aj in allj) evoResids[(pMax+1):T,] = evoResids[(pMax+1):T,] - tcrossprod(mu[((pMax+1):T - aj),], sj[aj]*Gp[,p.inds[aj]:(p.inds[aj+1] - 1)])
    
    if(useFDLM){
      # Sample the relevant parameters:
      fdlmSamp = sampleFDLM(evoResids, covParams, fdlmParams, fixSigma_eta, sampleFLCs); covParams = fdlmSamp$covParams; fdlmParams = fdlmSamp$fdlmParams; PhiMat = covParams$PhiMat; sigmaj2 = covParams$sigmaj2; sigma_eta = covParams$sigma_eta
      
      # Compute the innovation covariance and its inverse using the FDLM simplifications:
      Keps = Kfun(PhiMat, diag(sigmaj2), sigma_eta); KepsInv = Kinvfun(PhiMat, sigmaj2, sigma_eta)
    } else {
      # GP covariance function: sample parameters and form the covariance (and inverse) matrix
      gpSamp = sampleGP(evoResids, gpParams, rhoInfo); Keps = gpSamp$Keps; KepsInv = gpSamp$KepsInv; gpParams = gpSamp$gpParams;
    }
    ######################################################
    # Observation error variance:
    ######################################################
    sigma_nu = sqrt(1/rgamma(1, shape = (0.001 + sum(!is.na(Y))/2), rate = (0.001 +sum((Y - muTot)^2, na.rm=TRUE)/2)))
    ######################################################
    # Sample the centered functions \mu_t 
    ######################################################
    
    # Select the DLM w/ the smallest necessary FAR lag:
    if(sum(sj) == 0){
      # p = 0, so no FAR model...
      jstar = 1; Tmat = matrix(0, nr=mAll,nc=mAll)
    } else{jstar = max(which(sj==1)); Tmat = Gp[, 1:(jstar*mAll)]}
    Model = Models[[jstar]]
    
    Model$y =  Y - muIntRep;  # Centering
    Model$H[,,1] = diag(sigma_nu^2, mAll); Model$T[1:mAll,,1] = Tmat;  Model$Q[1:mAll,1:mAll,1] = Model$P1[1:mAll,1:mAll] =  Keps
    if((pMax > 1 || !useFDLM) && any(abs(eigen(Model$T[,,1], only.values=TRUE)$values) > 1)){
      # Use FFBS, which is more stable when the evolution is nonstationary:
      dlmMod = dlm(FF = Model$Z[,,1], V = Model$H[,,1], GG = Model$T[,,1], W = Model$Q[,,1], m0 = Model$a1, C0 = Model$P1)
      mutemp = try(dlmBSample(dlmFilter(Model$y, dlmMod)))
      if(class(mutemp) == "try-error"){print('Did not sample mu')} else mu = mutemp[-1,1:mAll]
    } else mu = simulateSSM(Model, "states", nsim = 1, antithetics=FALSE, filtered=FALSE)[,1:mAll,1]

    # And the same, but with the forecast data:
    # Note: these parameters are conditional on data from times t=1,...,T
    ModelFore = ModelsFore[[jstar]]; ModelFore$y = Ytot - tcrossprod(rep(1, Ttot), muInt)
    ModelFore$H[,,1] = diag(sigma_nu^2, mAll); ModelFore$T[1:mAll,,1] = Tmat;  ModelFore$Q[1:mAll,1:mAll,1] = ModelFore$P1[1:mAll,1:mAll] = Keps
    # Filtering produces one-step forecasts
    kfstemp = KFS(ModelFore, filtering="state", smoothing="none")
    
    # For h-step forecast (h-1 steps ahead of 1-step forecast)
    Ghm1 = ModelFore$T[,,1]; if(h > 2){for(hi in 1:(h-2)) Ghm1 = Ghm1%*%ModelFore$T[,,1]} 
    
    # Forecasting Options: use conditional expectation, or simulate and then average (the latter is slower but often better)
    #muFore =  tcrossprod(rep(1, forHoriz), muInt) + kfstemp$a[(T+1):Ttot,1:mAll]
    muForeH = tcrossprod(rep(1, forHoriz), muInt) +  tcrossprod(kfstemp$a[(T+1):Ttot,], Ghm1)[,1:mAll]     #muForeH = tcrossprod(rep(1, forHoriz), muInt) +  tcrossprod(kfstemp$a[(T+1):Ttot,1:mAll], Ghm1)
    for(ti in (T+1):Ttot) muFore[ti - T, ] = muInt + kfstemp$a[ti,1:mAll] + crossprod(chol(kfstemp$P[1:mAll,1:mAll,ti]), rnorm(mEval)) #muForeH[ti - T, ] = muInt + (Ghm1%*%kfstemp$a[ti,])[1:mAll,]
    
    ######################################################
    # Overall mean function:
    ######################################################
    muIntSamp = sampleMuInt(Y - mu, thetaInt, sigma_nu, muIntInfo, coefPriorPrec); muInt = muIntSamp$muInt; thetaInt = muIntSamp$thetaInt
    muIntRep = tcrossprod(rep(1, T), muInt)
    # What we're really interested in: the non-centered parameter
    muTot = muIntRep; muTot[,match(tauEval, tauAll)] = muTot[,match(tauEval, tauAll)] + mu # estimates of Y_t
    ######################################################
    # Store the MCMC samples
    ######################################################
    if((nsi > burnin && ((nsi-burnin)%%thin==0))){
      postMuTotFore[(nsi-burnin)/thin,,] = muFore; postMuTotForeH[(nsi-burnin)/thin,,] = muForeH;
      if(selectLagP) postSj[(nsi-burnin)/thin,] = sj
    }
    # Check the time remaining:
    computeTimeRemaining(nsi, timeri, nsims)
  }
  
  # Some iteration-specific information to record:
  compTimesAll[niter] = proc.time()[3] - timeri             # Computation time
  if(selectLagP) propSelectedAll[niter,] = colMeans(postSj) # Probability of inclusion
  if(useFDLM) {JeAll[niter] = ncol(PhiMat)}                 # Number of basis functions (fdlm) OR rho (GP)
  
  # Forecasts:
  muTotFore = colMeans(postMuTotFore)
  muTotForeH = colMeans(postMuTotForeH)
  
  ############################################################
  errRW = errFAR  = errVAR = errVARy = errMean = errFARclass = errDRA06 = errDRA06init = errSES = 0
  errRWh = errFARh  = errVARh = errVARyh = errMeanh = errFARclassh = errDRA06h = errDRA06inith = errSESh = 0
  
  # SSE (d=2) or SAE (d=1)?
  d = 2 
  
  #Ytot0 = fillNA(Ytot, tauEval, linearInterp=TRUE) # fill in missing values
  Ytot0 = fillNA(Ytotobs, tauObs, linearInterp=TRUE) # fill in missing values
  
  neverObs = which(abs(colSums(is.na(Yobs)) - T) <10^-10) # maturities never observed 
  
  # Just get the basis:
  vals = computeFPCA(Ytot0, tauObs, 0.95); basisY = vals$basisY
  
  for(i in (T+1):Ttot){
    Y0t = Ytot0[1:(i-1),]; cc = !is.na(Ytotobs[i,]); if(i <= Ttot - h + 1) cch = !is.na(Ytotobs[i+h-1,])
    
    meanYfd = mean.fd(Data2fd(tauObs, t(Y0t), basisY)); muInt0t = eval.fd(tauObs, meanYfd); muIntRep0t = matrix(rep(muInt0t, nrow(Y0t)),nrow=nrow(Y0t), byrow=TRUE)
    
    pcaVals = computeFPCA(Y0t - muIntRep0t, tauObs, 0.95); fpcs = pcaVals$fpcs; fpcScores = pcaVals$fpcScores; basisY = pcaVals$basisY; colnames(fpcScores) = 1:ncol(fpcScores)
    VARfpc = matrix(unlist(lapply(VAR(fpcScores, p=1, "none")$varresult, coef)), nrow=ncol(fpcScores), byrow=TRUE)
    
    # For VAR-y: check to see if sparse-fixed (if so, only run VAR on the obs points, then interpolate)
    if(length(neverObs) > 0){
      VARy = matrix(unlist(lapply(VAR(Y0t[,-neverObs] - muIntRep0t[,-neverObs], p=1, "none")$varresult, coef)), nrow=ncol(Y0t[,-neverObs]), byrow=TRUE)
    } else VARy = matrix(unlist(lapply(VAR(Y0t - muIntRep0t, p=1, "none")$varresult, coef)), nrow=ncol(Y0t), byrow=TRUE)
    
    # RW model:
    if(sum(cc) > 0) errRW = errRW + sum(abs(Ytotobs[i,cc] - Y0t[i-1,cc])^d, na.rm=TRUE)/sum(cc)
    if(i <= Ttot - h + 1) {
      if(sum(cch) > 0) errRWh = errRWh + sum(abs(Ytotobs[i+h-1,cch] - Y0t[i-1,cch])^d, na.rm=TRUE)/sum(cch)
    }
    
    # FAR model:
    if(sum(cc) > 0) errFAR = errFAR + sum(abs(Ytotobs[i,cc] - muTotFore[i-T,match(tau0, tauEval0)[cc]])^d, na.rm=TRUE)/sum(cc)
    if(i <= Ttot - h + 1) {
      if(sum(cch) > 0) errFARh = errFARh + sum(abs(Ytotobs[i+h-1,cch] - muTotForeH[i-T,match(tau0, tauEval0)[cch]])^d, na.rm=TRUE)/sum(cch)
    }
    
    # FAR (classic):
    if(sum(cc) > 0) errFARclass = errFARclass + sum(abs(Ytotobs[i,cc] - muInt0t[cc] - classicFARfore(tauObs[cc], pcaVals, i-1))^d, na.rm=TRUE)/sum(cc)
    
    # VAR on FPCs:
    if(sum(cc) > 0) errVAR = errVAR + sum(abs(Ytotobs[i,cc] - muInt0t[cc] - eval.basis(basisY, tauObs[cc])%*%fpcs%*%VARfpc%*%fpcScores[i-1,])^d, na.rm=TRUE)/sum(cc)
    if(i <= Ttot - h + 1){
      VARfpch = VARfpc; for(hi in 1:(h-1)) VARfpch = VARfpch%*%VARfpc
      if(sum(cch) > 0) errVARh = errVARh + sum(abs(Ytotobs[i+h-1,cch] - muInt0t[cch] - eval.basis(basisY, tauObs[cch])%*%fpcs%*%VARfpch%*%fpcScores[i-1,])^d, na.rm=TRUE)/sum(cch)
    }
    
    # VAR on Y
    if(length(neverObs) > 0){
      yhatVar = VARy%*%Y0t[i-1,-neverObs]; yhatVarInt = splinefun(tauObs[-neverObs], yhatVar)(tauObs)
      if(sum(cc) > 0) errVARy = errVARy + sum(abs(Ytotobs[i, cc] - muInt0t[cc] - yhatVar)^d, na.rm=TRUE)/sum(cc)
      if(i <= Ttot - h + 1){
        VARyh = VARy; for(hi in 1:(h-1)) VARyh = VARyh%*%VARy
        yhatVar = VARyh%*%Y0t[i-1,-neverObs]; yhatVarInt = splinefun(tauObs[-neverObs], yhatVar)(tauObs)
        if(sum(cch) > 0) errVARyh = errVARyh + sum(abs(Ytotobs[i+h-1, cch] - muInt0t[cch] - yhatVar)^d, na.rm=TRUE)/sum(cch)
      }
    } else {
      if(sum(cc) > 0) errVARy = errVARy + sum(abs(Ytotobs[i, cc] - muInt0t[cc] - (VARy%*%(Y0t[i-1,] - muInt0t))[cc])^d, na.rm=TRUE)/sum(cc)
      if(i <= Ttot - h + 1){
        VARyh = VARy; for(hi in 1:(h-1)) VARyh = VARyh%*%VARy
        if(sum(cch) > 0) errVARyh = errVARyh + sum(abs(Ytotobs[i+h-1, cch] - muInt0t[cch] - (VARyh%*%(Y0t[i-1,] - muInt0t))[cch])^d, na.rm=TRUE)/sum(cch)
      }
    }
    
    # Simply using the mean as predictor:
    if(sum(cc) > 0) errMean = errMean + sum(abs(Ytotobs[i,] - muInt0t)^d, na.rm=TRUE)/sum(cc)
    if(i <= Ttot - h + 1){
      if(sum(cch) > 0) errMeanh = errMeanh + sum(abs(Ytotobs[i+h-1,] - muInt0t)^d, na.rm=TRUE)/sum(cch)
    }
    
    # Simple functional exponential smoother: 
    if(sum(cc) > 0) errSES = errSES + sum(abs(Ytotobs[i,] - apply(Ytotobs[1:(i-1),cc], 2, function(x) ses(x, h = 1)$mean[1]))^d, na.rm=TRUE)/sum(cc)
    if(i <= Ttot - h + 1){
      if(sum(cch) > 0) errSESh = errSESh + sum(abs(Ytotobs[i+h-1,] -  apply(Ytotobs[1:(i-1),cch], 2, function(x) ses(x, h = h)$mean[h]))^d, na.rm=TRUE)/sum(cch)
    }
  
    # DRA06 estimate (Note: if unstable, leave nonlinear NS parameter fixed at 0.0609)
    yfores = forecastDRA(yi = Ytotobs[1:(i-1),], tau0, yiInterp = Y0t, h = h, useDiagonalQ = TRUE, includeIntercept = TRUE, estimateLambda = TRUE)
    if(any(abs(yfores$yfore) > 10^3)) yfores = forecastDRA(yi = Ytotobs[1:(i-1),], tau0, yiInterp = Y0t, h = h, useDiagonalQ = TRUE, includeIntercept = TRUE, estimateLambda = FALSE)
    if(sum(cc) > 0) errDRA06 = errDRA06 + sum(abs(Ytotobs[i,cc] - yfores$yfore[cc])^d, na.rm=TRUE)/sum(cc)
    if(i <= Ttot - h + 1){
      if(sum(cch) > 0) errDRA06h = errDRA06h + sum(abs(Ytotobs[i+h-1,cch] - yfores$yforeh[cch])^d, na.rm=TRUE)/sum(cch)
    }
    
    # DRA06 initialization-based estimate:
    if(sum(cc) > 0) errDRA06init = errDRA06init + sum(abs(Ytotobs[i,cc] - yfores$yfore0[cc])^d, na.rm=TRUE)/sum(cc)
    if(i <= Ttot - h + 1){
      if(sum(cch) > 0) errDRA06inith = errDRA06inith + sum(abs(Ytotobs[i+h-1,cch] - yfores$yfore0h[cch])^d, na.rm=TRUE)/sum(cch)
    }
  }
  (errAll[niter,] = 1/(Ttot-T)*rbind(errRW, errMean, errSES, errVARy, errDRA06, errDRA06init, errFARclass, errVAR, errFAR))
  (errAllh[niter,] = 1/(Ttot - T - h + 1)*rbind(errRWh, errMeanh, errSESh, errVARyh, errDRA06h, errDRA06inith, errFARclassh, errVARh, errFARh))

  print('###############################################')
  computeTimeRemaining(niter, timer0, Niters, nrep=1)
  print('###############################################')
}
RMSE = sqrt(errAll)
RMSEh = sqrt(errAllh)
